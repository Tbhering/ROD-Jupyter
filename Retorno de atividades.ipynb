{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySFPNg8ptjVY"
   },
   "source": [
    "Ler arquivos wpp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1737629289153,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "8ec-ZRonseqv",
    "outputId": "9a66f82d-27b1-4e84-bda1-458461f93b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorando linha irrelevante: 23/01/2025 01:47 - Paulo Super Esp: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO: 22/01\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO:Desmontagem\n",
      "-> Linha relevante encontrada: TAG: 2PE03\n",
      "-> Linha relevante encontrada: ORDEM:202500155907\n",
      "-> Linha relevante encontrada: DESCRIÇÃO:\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME:Passarela\n",
      "-> Linha relevante encontrada: COMPRIMENTO: 3,20\n",
      "-> Linha relevante encontrada: LARGURA:1,05\n",
      "-> Linha relevante encontrada: ALTURA:4,00\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:17:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:17:10\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE: 19:00\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:17:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:17:10\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA:\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:\n",
      "Ignorando linha irrelevante: 23/01/2025 01:47 - Paulo Super Esp: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO: 22/01/25\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO:Desmontagem\n",
      "-> Linha relevante encontrada: TAG: 2PE01\n",
      "-> Linha relevante encontrada: ORDEM:202500155806\n",
      "-> Linha relevante encontrada: DESCRIÇÃO:\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME:Torre\n",
      "-> Linha relevante encontrada: COMPRIMENTO: 2,50\n",
      "-> Linha relevante encontrada: LARGURA:1,05\n",
      "-> Linha relevante encontrada: ALTURA:4,00\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:19:30\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:20:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE: 21:30\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:19:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:19:40\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA:\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:\n",
      "-> Linha relevante encontrada: 23/01/2025 08:36 - +55 31 9781-5761: Aguardando o operador para realizar PTS TCLD-TC-6042\n",
      "Ignorando linha irrelevante: 23/01/2025 08:43 - +55 31 9562-6016: Aguardando liberação do bloqueio  da PE6009 e PE6010 na central de bloqueio\n",
      "Ignorando linha irrelevante: 23/01/2025 08:47 - +55 31 9785-1071: Aguardando liberação de Bloqueio do AG6301\n",
      "Ignorando linha irrelevante: 23/01/2025 09:07 - +55 31 9785-1071: Ainda no aguardo do bloqueio,bloqueio ainda não chegou na central de bloqueio\n",
      "-> Linha relevante encontrada: 23/01/2025 09:28 - +55 31 9781-5761: PTS liberado\n",
      "-> Linha relevante encontrada: 23/01/2025 09:52 - +55 31 9562-6016: PE6009 e PE6010  BLOQUEIO LIBERADO AGORA\n",
      "Ignorando linha irrelevante: 23/01/2025 09:54 - +55 31 9785-1071: Bloqueoio liberado agora\n",
      "-> Linha relevante encontrada: 23/01/2025 09:58 - +55 31 9785-1071: Aguardando operador liberar PTS\n",
      "Ignorando linha irrelevante: 23/01/2025 09:59 - +55 31 9785-1071: Já foi solicitada\n",
      "-> Linha relevante encontrada: 23/01/2025 10:09 - +55 31 9562-6016: Aguardando operador pra emitir PTS na classificação\n",
      "-> Linha relevante encontrada: 23/01/2025 10:26 - +55 31 9785-1071: PTS liberada\n",
      "Ignorando linha irrelevante: 23/01/2025 10:33 - +55 31 9747-7452: Atividade da RA 9030 ainda nao pode realizada(tubulação vazando)\n",
      "Ignorando linha irrelevante: 23/01/2025 10:38 - +55 31 9781-5761: Equipe desviada para realizar atividade da TC-6015 atualização de Denis vale\n",
      "-> Linha relevante encontrada: 23/01/2025 10:47 - +55 31 9785-1071: Aguardando operador liberar PTS no último dá flotação\n",
      "Ignorando linha irrelevante: 23/01/2025 10:47 - +55 31 9785-1071: Pts já solicitada\n",
      "-> Linha relevante encontrada: 23/01/2025 11:02 - +55 31 9785-1071: Até o momento operador ainda não apareceu para liberar PTS\n",
      "Ignorando linha irrelevante: 23/01/2025 11:18 - +55 31 9781-5761: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO:23/01/2025\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO: montagem de andaime finalizada\n",
      "-> Linha relevante encontrada: TAG:TC-6042-09TC\n",
      "-> Linha relevante encontrada: ORDEM:202500258690\n",
      "-> Linha relevante encontrada: DESCRIÇÃO: montagem de andaime para vocalização acessar o contrapiso TC-6042\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME: escada de acesso\n",
      "-> Linha relevante encontrada: COMPRIMENTO:1.90\n",
      "-> Linha relevante encontrada: LARGURA:1.90\n",
      "-> Linha relevante encontrada: ALTURA:4.000\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:08:10\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:09:05\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE:10:13\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:NÃ\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:NÃ\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:09:01\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:09:05\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO: bloqueio exclusivo\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO: bloqueio exclusivo\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA:NÃ\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:NÃ\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:NÃ\n",
      "Ignorando linha irrelevante: 23/01/2025 11:28 - +55 31 9781-5761: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO:23/01/2025\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO: montagem de andaime finalizado\n",
      "-> Linha relevante encontrada: TAG:TC-6015\n",
      "-> Linha relevante encontrada: ORDEM:202500399129\n",
      "-> Linha relevante encontrada: DESCRIÇÃO:forramento da TC-6015 para vulcanização dá reparo na Correia\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME: forramento\n",
      "-> Linha relevante encontrada: COMPRIMENTO:2.000\n",
      "-> Linha relevante encontrada: LARGURA:1.50\n",
      "-> Linha relevante encontrada: ALTURA:1.75\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:10:45\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:10:55\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE:11:28\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:NÃ\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:NÃ\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:NÃ\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO: vale\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA:NÃ\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:NÃ\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:NÃ\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:NÃ\n",
      "Ignorando linha irrelevante: 23/01/2025 11:55 - +55 31 8221-6491: Tc 5007 montado ✅\n",
      "Ignorando linha irrelevante: 23/01/2025 12:16 - +55 31 9781-5761: Mensagem apagada\n",
      "Ignorando linha irrelevante: 23/01/2025 12:17 - +55 31 9781-5761: Aguardando vulcanização retirar o bloqueio exclusivo para bloquear o bloqueio normal\n",
      "Ignorando linha irrelevante: 23/01/2025 12:33 - +55 31 8221-6491: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO: 23/01/25\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO:MONTADO\n",
      "-> Linha relevante encontrada: TAG:tc5007\n",
      "-> Linha relevante encontrada: ORDEM:202405254103\n",
      "-> Linha relevante encontrada: DESCRIÇÃO: mont/desmont\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME:SIMPLES\n",
      "-> Linha relevante encontrada: COMPRIMENTO:2.00\n",
      "-> Linha relevante encontrada: LARGURA:1.00\n",
      "-> Linha relevante encontrada: ALTURA: 2.50\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:08:30\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:10:10\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE:11:50\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:09:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:09:40\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO:09:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO:09:30\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA: N/A\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA: N/A\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:\n",
      "Ignorando linha irrelevante: 23/01/2025 12:52 - +55 31 9747-7452: ---------------------------------------------------\n",
      "-> Linha relevante encontrada: RETORNO DAS ATIVIDADES\n",
      "-> Linha relevante encontrada: DATA DE EXECUÇÃO: 23/01/25\n",
      "-> Linha relevante encontrada: STATUS DA EXECUÇÃO:MONTADO\n",
      "-> Linha relevante encontrada: TAG:AG6301\n",
      "-> Linha relevante encontrada: ORDEM:202500397783\n",
      "-> Linha relevante encontrada: DESCRIÇÃO:  MONTAGEM DE ANDAIME PARA SUBSTITUIR CARRETEL\n",
      "-> Linha relevante encontrada: TIPO DE ANDAIME:SIMPLES\n",
      "-> Linha relevante encontrada: COMPRIMENTO:2,10\n",
      "-> Linha relevante encontrada: LARGURA:1,80\n",
      "-> Linha relevante encontrada: ALTURA: 4,00\n",
      "-> Linha relevante encontrada: HORÁRIOS\n",
      "-> Linha relevante encontrada: HORÁRIO DE DISPONIBILIDADE:08:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE INÍCIO DA ATIVIDADE:11:00\n",
      "-> Linha relevante encontrada: HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE:12:35\n",
      "-> Linha relevante encontrada: CANCELAMENTO\n",
      "-> Linha relevante encontrada: RAZÃO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: HORÁRIO DO CANCELAMENTO:\n",
      "-> Linha relevante encontrada: DESVIO DE ATIVIDADE\n",
      "-> Linha relevante encontrada: HORÁRIO DO DESVIO:\n",
      "-> Linha relevante encontrada: PTS\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PTS:10:45\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PTS:10:55\n",
      "-> Linha relevante encontrada: BLOQUEIO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DO BLOQUEIO:\n",
      "-> Linha relevante encontrada: LIMPEZA\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA LIMPEZA: N/A\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA LIMPEZA: N/A\n",
      "-> Linha relevante encontrada: AGUARDANDO ORDEM DE SERVIÇO\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA OM:\n",
      "-> Linha relevante encontrada: HORÁRIO DE RECEBIMENTO DA OM:\n",
      "-> Linha relevante encontrada: PET\n",
      "-> Linha relevante encontrada: HORÁRIO DE SOLICITAÇÃO DA PET:\n",
      "-> Linha relevante encontrada: HORÁRIO DE LIBERAÇÃO DA PET:\n",
      "\n",
      "Processamento concluído!\n",
      "Linhas processadas: 374\n",
      "Linhas copiadas para o relatório: 356\n",
      "Linhas ignoradas: 17\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def filtrar_relatorio(arquivo_entrada, arquivo_saida):\n",
    "    # Define padrões para capturar seções importantes\n",
    "    padrao_relevante = re.compile(r\"(RETORNO DAS ATIVIDADES|HORÁRIOS|CANCELAMENTO|DESVIO DE ATIVIDADE|PTS|BLOQUEIO|LIMPEZA|AGUARDANDO ORDEM DE SERVIÇO|PET|DATA DE EXECUÇÃO|STATUS DA EXECUÇÃO|TAG|ORDEM|DESCRIÇÃO|TIPO DE ANDAIME|QTD\\. DE PESSOAS|COMPRIMENTO|LARGURA|ALTURA|HORÁRIO)\")\n",
    "    padrao_irrelevante = re.compile(r\"^\\d{2}/\\d{2}/\\d{4} \\d{2}:\\d{2} - .+:.*\")\n",
    "\n",
    "    # Contadores para diagnóstico\n",
    "    linhas_processadas = 0\n",
    "    linhas_copiadas = 0\n",
    "    linhas_ignoradas = 0\n",
    "\n",
    "    try:\n",
    "        # Verifica se o arquivo de entrada existe\n",
    "        if not arquivo_entrada.exists():\n",
    "            print(f\"Erro: Arquivo de entrada '{arquivo_entrada}' não encontrado.\")\n",
    "            return\n",
    "\n",
    "        with arquivo_entrada.open(\"r\", encoding=\"utf-8\") as entrada, arquivo_saida.open(\"w\", encoding=\"utf-8\") as saida:\n",
    "            copiar = False\n",
    "            for linha in entrada:\n",
    "                linhas_processadas += 1  # Incrementa o total de linhas processadas\n",
    "                # Verifica se a linha é relevante\n",
    "                if padrao_relevante.search(linha):\n",
    "                    copiar = True\n",
    "                    print(f\"-> Linha relevante encontrada: {linha.strip()}\")\n",
    "                elif padrao_irrelevante.match(linha):\n",
    "                    copiar = False\n",
    "                    print(f\"Ignorando linha irrelevante: {linha.strip()}\")\n",
    "                    linhas_ignoradas += 1\n",
    "                    continue  # Passa para a próxima linha\n",
    "\n",
    "                # Copia linhas relevantes\n",
    "                if copiar:\n",
    "                    saida.write(linha)\n",
    "                    linhas_copiadas += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante o processamento: {e}\")\n",
    "        return\n",
    "\n",
    "    # Diagnóstico final\n",
    "    print(\"\\nProcessamento concluído!\")\n",
    "    print(f\"Linhas processadas: {linhas_processadas}\")\n",
    "    print(f\"Linhas copiadas para o relatório: {linhas_copiadas}\")\n",
    "    print(f\"Linhas ignoradas: {linhas_ignoradas}\")\n",
    "\n",
    "# Define o diretório atual e os caminhos relativos dos arquivos\n",
    "diretorio_atual = Path.cwd()  # Obtém o diretório de trabalho atual\n",
    "arquivo_entrada = diretorio_atual / \"wpp.txt\"\n",
    "arquivo_saida = diretorio_atual / \"relatorio_filtrado.txt\"\n",
    "\n",
    "# Executa o filtro\n",
    "filtrar_relatorio(arquivo_entrada, arquivo_saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xoiA-fcvNPA"
   },
   "source": [
    "TRANSFORMAR .TXT EM .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1737629455645,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "5tTX-jeCvS3r",
    "outputId": "210cef23-af2c-4fd0-fea4-3f7bbfe6f151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV gerado com sucesso em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_final.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def gerar_csv(arquivo_entrada, arquivo_saida_csv):\n",
    "    # Define as colunas do CSV\n",
    "    colunas = [\n",
    "        \"DATA DE EXECUÇÃO\", \"STATUS DA EXECUÇÃO\", \"STATUS DO PLANEJAMENTO\", \"TAG\",\n",
    "        \"ORDEM\", \"DESCRIÇÃO\", \"QTD PESSOAS\", \"TIPO DE ANDAIME\", \"QUANTIDADE DE ANDAIMES\",\n",
    "        \"COMPRIMENTO\", \"LARGURA\", \"ALTURA\",\n",
    "        \"HORÁRIO DE DISPONIBILIDADE\", \"HORÁRIO DE INÍCIO DA ATIVIDADE\", \"HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE\",\n",
    "        \"PREPARAÇÃO DE MATERIAL\", \"RAZÃO DO CANCELAMENTO\", \"HORÁRIO DO CANCELAMENTO\",\n",
    "        \"RAZÃO DO DESVIO\", \"HORÁRIO DO DESVIO\",\n",
    "        \"HORÁRIO DE SOLICITAÇÃO DA PTS\", \"HORÁRIO DE LIBERAÇÃO DA PTS\",\n",
    "        \"HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO\", \"HORÁRIO DE LIBERAÇÃO DO BLOQUEIO\",\n",
    "        \"HORÁRIO DE SOLICITAÇÃO DA LIMPEZA\", \"HORÁRIO DE LIBERAÇÃO DA LIMPEZA\",\n",
    "        \"HORÁRIO DE SOLICITAÇÃO DA OM\", \"HORÁRIO DE RECEBIMENTO DA OM\",\n",
    "        \"HORÁRIO DE SOLICITAÇÃO DA PET\", \"HORÁRIO DE LIBERAÇÃO DA PET\"\n",
    "    ]\n",
    "\n",
    "    # Define os padrões para capturar as informações\n",
    "    padroes = {coluna: re.compile(fr\"{coluna}: ?(.*)\", re.IGNORECASE) for coluna in colunas}\n",
    "\n",
    "    # Processa o arquivo e cria o CSV\n",
    "    try:\n",
    "        # Verifica se o arquivo de entrada existe\n",
    "        if not arquivo_entrada.exists():\n",
    "            print(f\"Erro: Arquivo de entrada '{arquivo_entrada}' não encontrado.\")\n",
    "            return\n",
    "\n",
    "        with arquivo_entrada.open(\"r\", encoding=\"utf-8\") as entrada, arquivo_saida_csv.open(\"w\", encoding=\"utf-8\", newline=\"\") as saida_csv:\n",
    "            writer = csv.DictWriter(saida_csv, fieldnames=colunas)\n",
    "            writer.writeheader()\n",
    "\n",
    "            dados_atual = {coluna: \"\" for coluna in colunas}  # Inicializa os dados de um relatório\n",
    "            for linha in entrada:\n",
    "                for coluna, padrao in padroes.items():\n",
    "                    match = padrao.search(linha)\n",
    "                    if match:\n",
    "                        dados_atual[coluna] = match.group(1).strip()\n",
    "\n",
    "                # Detecta o fim de um relatório para salvar os dados no CSV\n",
    "                if \"HORÁRIO DE LIBERAÇÃO DA PET\" in linha.upper():\n",
    "                    writer.writerow(dados_atual)\n",
    "                    dados_atual = {coluna: \"\" for coluna in colunas}  # Reseta os dados para o próximo relatório\n",
    "\n",
    "        print(f\"Arquivo CSV gerado com sucesso em: {arquivo_saida_csv}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante o processamento: {e}\")\n",
    "\n",
    "# Define o diretório atual e os caminhos relativos dos arquivos\n",
    "diretorio_atual = Path.cwd()  # Obtém o diretório de trabalho atual\n",
    "arquivo_entrada = diretorio_atual / \"relatorio_filtrado.txt\"\n",
    "arquivo_saida_csv = diretorio_atual / \"relatorio_final.csv\"\n",
    "\n",
    "# Executa o processamento\n",
    "gerar_csv(arquivo_entrada, arquivo_saida_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njYGUmBUxWtW"
   },
   "source": [
    "TRATAR COLUNA DE STATUS NO ARQUIVO.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1737629671592,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "RZH1kifdxdiR",
    "outputId": "7a064f3d-97c1-4d15-bcee-b35b6e3c5362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 13:23:42,935 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-montagem.txt.\n",
      "2025-01-25 13:23:42,937 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-montagem.txt: ['montagem andaime', 'montagn di andaim', 'montagen de andaime', 'motagen', 'muntagin'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:42,939 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-desmontagem.txt.\n",
      "2025-01-25 13:23:42,940 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-desmontagem.txt: ['desmontagem andaime', 'desmontagen', 'desmonte', 'desmontagem de andami', 'desmontang'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:42,943 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-montagem-e-desmontagem.txt.\n",
      "2025-01-25 13:23:42,959 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-montagem-e-desmontagem.txt: ['montj e desmotem', 'montaem dismontjem', 'montdgem e desmonte', 'mont e desmont', 'montagi desmontagi'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:42,962 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-adequacoes.txt.\n",
      "2025-01-25 13:23:42,964 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-adequacoes.txt: ['adekuacao', 'adekuação', 'adekwassão', 'adequassão', 'adequasão'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:42,967 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-cancelado.txt.\n",
      "2025-01-25 13:23:42,969 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-cancelado.txt: ['cancelado', 'cancelado hoje', 'cancelado ontem', 'cancelado amanhã', 'cancelado parcialmente'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:42,971 - INFO - Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha 3 do arquivo C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-em andamento.txt.\n",
      "2025-01-25 13:23:42,973 - INFO - Variações carregadas de C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-txt\\variacoes-erros-em andamento.txt: ['montado 5%', 'montado 10%', 'montado 15%', 'montado 20%', 'montado 25%'] (mostrando até 5 itens)\n",
      "2025-01-25 13:23:43,024 - INFO - Arquivo carregado com 6 linhas e 30 colunas.\n",
      "2025-01-25 13:23:43,026 - INFO - Status 'Desmontagem' padronizado para 'DESMONTAGEM'.\n",
      "2025-01-25 13:23:43,027 - INFO - Status 'Desmontagem' padronizado para 'DESMONTAGEM'.\n",
      "2025-01-25 13:23:43,029 - INFO - Status 'montagem de andaime finalizada' padronizado para 'MONTAGEM'.\n",
      "2025-01-25 13:23:43,030 - INFO - Status 'Montagem em andamento' padronizado para 'MONTAGEM'.\n",
      "2025-01-25 13:23:43,031 - INFO - Status 'MONTADO' padronizado para 'MONTAGEM'.\n",
      "2025-01-25 13:23:43,033 - INFO - Status 'MONTADO' padronizado para 'MONTAGEM'.\n",
      "2025-01-25 13:23:43,035 - INFO - Correção da coluna 'STATUS DA EXECUÇÃO' realizada com sucesso.\n",
      "2025-01-25 13:23:43,038 - INFO - Arquivo tratado salvo em: C:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\arquivos-gerados\\arquivos-csv\\relatorio_tratado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configuração de logging para rastreamento detalhado\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def validar_formato_variacoes(caminho_arquivo):\n",
    "    \"\"\"Valida se o arquivo possui o formato esperado.\"\"\"\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "            linhas = [line.strip() for line in f if line.strip()]\n",
    "            if len(linhas) < 3:\n",
    "                logging.warning(f\"O arquivo {caminho_arquivo} possui menos de 3 linhas.\")\n",
    "                return False\n",
    "            if not linhas[0].startswith('| STATUS DA EXECUÇÃO CORRETO'):\n",
    "                logging.warning(f\"A primeira linha do arquivo {caminho_arquivo} não corresponde ao cabeçalho esperado.\")\n",
    "                return False\n",
    "            if not any(line.startswith('| STATUS DA EXECUÇÃO INCORRETOS') for line in linhas):\n",
    "                logging.warning(f\"O arquivo {caminho_arquivo} não contém o cabeçalho para variações incorretas.\")\n",
    "                return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao validar o formato do arquivo {caminho_arquivo}: {e}\")\n",
    "        return False\n",
    "\n",
    "def carregar_variacoes(caminho_arquivo):\n",
    "    \"\"\"Carrega as variações de erro de um arquivo de forma segura.\"\"\"\n",
    "    if not validar_formato_variacoes(caminho_arquivo):\n",
    "        logging.warning(f\"Formato inválido no arquivo de variações: {caminho_arquivo}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "            linhas = [line.strip().lower() for line in f if line.strip()]\n",
    "            # Localiza a seção 'STATUS DA EXECUÇÃO INCORRETOS'\n",
    "            for i, line in enumerate(linhas):\n",
    "                if \"| status da execução incorretos\" in line:\n",
    "                    logging.info(f\"Cabeçalho 'STATUS DA EXECUÇÃO INCORRETOS' encontrado na linha {i} do arquivo {caminho_arquivo}.\")\n",
    "                    variacoes = linhas[i + 2:]  # Pula o cabeçalho e separador\n",
    "                    # Remove o caractere '|' e espaços desnecessários\n",
    "                    variacoes = [line.replace('|', '').strip() for line in variacoes if line.startswith('|')]\n",
    "                    if variacoes:\n",
    "                        logging.info(f\"Variações carregadas de {caminho_arquivo}: {variacoes[:5]} (mostrando até 5 itens)\")\n",
    "                    else:\n",
    "                        logging.warning(f\"Nenhuma variação encontrada após o cabeçalho no arquivo {caminho_arquivo}.\")\n",
    "                    return variacoes\n",
    "            logging.warning(f\"Seção 'STATUS DA EXECUÇÃO INCORRETOS' não encontrada no arquivo {caminho_arquivo}.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao carregar as variações do arquivo {caminho_arquivo}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def tratar_status(status, variacoes_status):\n",
    "    \"\"\"Trata os valores de 'STATUS DA EXECUÇÃO' para padronizar conforme variações, incluindo combinações.\"\"\"\n",
    "    status_original = status  # Preserve o valor original para depuração\n",
    "    status = status.lower() if isinstance(status, str) else \"\"\n",
    "\n",
    "    # Priorizar a categoria 'MONTAGEM E DESMONTAGEM'\n",
    "    if 'MONTAGEM E DESMONTAGEM' in variacoes_status:\n",
    "        variacoes_combinadas = variacoes_status['MONTAGEM E DESMONTAGEM']\n",
    "        if any(variacao in status for variacao in variacoes_combinadas):\n",
    "            logging.info(f\"Status '{status_original}' padronizado para 'MONTAGEM E DESMONTAGEM'.\")\n",
    "            return 'MONTAGEM E DESMONTAGEM'\n",
    "\n",
    "    # Verifica categorias individuais\n",
    "    for status_corrente, variacoes in variacoes_status.items():\n",
    "        if status_corrente != 'MONTAGEM E DESMONTAGEM':  # Ignora combinações nesta etapa\n",
    "            if any(variacao in status for variacao in variacoes):\n",
    "                logging.info(f\"Status '{status_original}' padronizado para '{status_corrente}'.\")\n",
    "                return status_corrente\n",
    "\n",
    "    # Adiciona nova variação se nenhuma correspondência for encontrada\n",
    "    logging.warning(f\"Status '{status_original}' não foi padronizado. Adicionando à lista de variações.\")\n",
    "    adicionar_nova_variacao(status_original)\n",
    "\n",
    "    # Recarregar variações e tentar novamente\n",
    "    for categoria, caminho in caminhos_variacoes.items():\n",
    "        variacoes_status[categoria] = carregar_variacoes(caminho)\n",
    "\n",
    "    # Repetir a lógica após recarregar\n",
    "    return tratar_status(status_original, variacoes_status)\n",
    "\n",
    "def adicionar_nova_variacao(status):\n",
    "    \"\"\"Adiciona um novo status não tratado ao arquivo correspondente.\"\"\"\n",
    "    status_lower = status.lower()\n",
    "\n",
    "    # Verifica a qual categoria o status pertence\n",
    "    for categoria, caminho in caminhos_variacoes.items():\n",
    "        # Categoria é associada se o nome dela estiver no status\n",
    "        if categoria.lower() in status_lower:\n",
    "            try:\n",
    "                with open(caminho, 'a', encoding='utf-8') as f:\n",
    "                    f.write(f\"| {status.strip()} |\\n\")\n",
    "                logging.info(f\"Nova variação '{status}' adicionada ao arquivo da categoria '{categoria}': {caminho}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao adicionar a variação '{status}' ao arquivo {caminho}: {e}\")\n",
    "                return\n",
    "\n",
    "    # Caso nenhuma correspondência seja encontrada, gerar um log de aviso\n",
    "    logging.warning(f\"Não foi possível associar o status '{status}' a nenhuma categoria existente.\")\n",
    "\n",
    "def adicionar_variacao(caminho_arquivo, nova_variacao):\n",
    "    \"\"\"Adiciona uma nova variação ao arquivo de variações.\"\"\"\n",
    "    try:\n",
    "        with open(caminho_arquivo, 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"{nova_variacao}\\n\")\n",
    "        logging.info(f\"Nova variação '{nova_variacao}' adicionada ao arquivo {caminho_arquivo}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao adicionar variação ao arquivo {caminho_arquivo}: {e}\")\n",
    "\n",
    "# Diretório base dinâmico\n",
    "base_dir = Path().resolve()\n",
    "\n",
    "# Configuração dos caminhos\n",
    "caminhos_variacoes = {\n",
    "    'MONTAGEM': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-montagem.txt\",\n",
    "    'DESMONTAGEM': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-desmontagem.txt\",\n",
    "    'MONTAGEM E DESMONTAGEM': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-montagem-e-desmontagem.txt\",\n",
    "    'ADEQUAÇÃO': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-adequacoes.txt\",\n",
    "    'CANCELADO': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-cancelado.txt\",\n",
    "    'EM ANDAMENTO': base_dir / \"arquivos-gerados\" / \"arquivos-txt\" / \"variacoes-erros-em andamento.txt\"\n",
    "}\n",
    "\n",
    "# Carregar as variações\n",
    "variacoes_status = {\n",
    "    status: carregar_variacoes(caminho) for status, caminho in caminhos_variacoes.items()\n",
    "}\n",
    "\n",
    "# Caminhos dos arquivos de entrada e saída\n",
    "caminho_arquivo = base_dir / \"relatorio_final.csv\"\n",
    "saida_dir = base_dir / \"arquivos-gerados\" / \"arquivos-csv\"\n",
    "caminho_saida = saida_dir / \"relatorio_tratado.csv\"\n",
    "\n",
    "# Garantir que o diretório de saída exista\n",
    "saida_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Processamento do arquivo CSV\n",
    "if not caminho_arquivo.exists():\n",
    "    logging.error(f\"Arquivo de entrada '{caminho_arquivo}' não encontrado.\")\n",
    "else:\n",
    "    try:\n",
    "        # Carregar o arquivo CSV\n",
    "        df = pd.read_csv(caminho_arquivo)\n",
    "        logging.info(f\"Arquivo carregado com {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "\n",
    "        # Padronizar os nomes das colunas\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Verificar e tratar a coluna 'STATUS DA EXECUÇÃO'\n",
    "        if 'STATUS DA EXECUÇÃO' in df.columns:\n",
    "            df['STATUS DA EXECUÇÃO'] = df['STATUS DA EXECUÇÃO'].apply(\n",
    "                lambda x: tratar_status(x, variacoes_status)\n",
    "            )\n",
    "            logging.info(\"Correção da coluna 'STATUS DA EXECUÇÃO' realizada com sucesso.\")\n",
    "\n",
    "            # Salvar o arquivo tratado\n",
    "            df.to_csv(caminho_saida, index=False)\n",
    "            logging.info(f\"Arquivo tratado salvo em: {caminho_saida}\")\n",
    "        else:\n",
    "            logging.error(\"Coluna 'STATUS DA EXECUÇÃO' não encontrada no arquivo.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro durante o processamento do arquivo: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEx5ARz8wmhn"
   },
   "source": [
    "Tratar Horas do arquivo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1737629693603,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "1Kgeb804xtpP",
    "outputId": "b1fe7dce-8446-4ad5-dbbc-b221b08c60a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo tratado com horas padronizadas salvo em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado_horas.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Caminho do arquivo gerado anteriormente\n",
    "diretorio_atual = Path.cwd()\n",
    "caminho_arquivo = diretorio_atual / \"relatorio_tratado.csv\"\n",
    "\n",
    "# Lista de colunas com campos de horas a serem padronizados\n",
    "colunas_horas = [\n",
    "    \"HORÁRIO DE DISPONIBILIDADE\", \"HORÁRIO DE INÍCIO DA ATIVIDADE\",\n",
    "    \"HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE\", \"RAZÃO DO CANCELAMENTO\",\n",
    "    \"HORÁRIO DO CANCELAMENTO\", \"HORÁRIO DO DESVIO\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA PTS\", \"HORÁRIO DE LIBERAÇÃO DA PTS\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO\", \"HORÁRIO DE LIBERAÇÃO DO BLOQUEIO\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA LIMPEZA\", \"HORÁRIO DE LIBERAÇÃO DA LIMPEZA\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA OM\", \"HORÁRIO DE RECEBIMENTO DA OM\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA PET\", \"HORÁRIO DE LIBERAÇÃO DA PET\"\n",
    "]\n",
    "\n",
    "# Função para padronizar os campos de hora\n",
    "def padronizar_horas(valor):\n",
    "    try:\n",
    "        # Verifica se o valor é string e não está vazio\n",
    "        if isinstance(valor, str) and valor.strip():\n",
    "            # Se o formato for apenas \"HH\", completa para \"HH:00:00\"\n",
    "            if len(valor) == 2 and valor.isdigit():\n",
    "                return f\"{valor}:00:00\"\n",
    "            # Se o formato for \"HH:MM\", completa para \"HH:MM:00\"\n",
    "            elif len(valor) == 5 and \":\" in valor:\n",
    "                return f\"{valor}:00\"\n",
    "            # Verifica se o valor já está no formato correto \"HH:MM:SS\"\n",
    "            elif len(valor) == 8 and \":\" in valor:\n",
    "                return valor\n",
    "        # Caso não seja válido, retorna o valor padrão \"00:00:00\"\n",
    "        return \"00:00:00\"\n",
    "    except Exception:\n",
    "        return \"00:00:00\"\n",
    "\n",
    "# Verifica se o arquivo de entrada existe\n",
    "if not caminho_arquivo.exists():\n",
    "    print(f\"Erro: Arquivo '{caminho_arquivo}' não encontrado.\")\n",
    "else:\n",
    "    # Carregar o arquivo .csv usando pandas\n",
    "    df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "    # Garantir que as colunas existem no DataFrame antes de aplicar a função\n",
    "    for coluna in colunas_horas:\n",
    "        if coluna in df.columns:\n",
    "            df[coluna] = df[coluna].apply(padronizar_horas)\n",
    "\n",
    "    # Caminho para o arquivo tratado\n",
    "    caminho_saida = diretorio_atual / \"relatorio_tratado_horas.csv\"\n",
    "    df.to_csv(caminho_saida, index=False)\n",
    "\n",
    "    print(f\"Arquivo tratado com horas padronizadas salvo em: {caminho_saida}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLtwdP8GywMB"
   },
   "source": [
    "Verificar se horas foram padronizadas corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1737629732571,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "ntIPVBQHy04e",
    "outputId": "81419e30-0244-46bc-9c2c-02edd0d2a08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as alterações foram feitas corretamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Definir os caminhos relativos dos arquivos\n",
    "caminho_arquivo = diretorio_atual / \"relatorio_tratado.csv\"\n",
    "caminho_saida = diretorio_atual / \"relatorio_tratado_horas.csv\"\n",
    "\n",
    "# Lista de colunas de horas para verificar\n",
    "colunas_horas = [\n",
    "    \"HORÁRIO DE DISPONIBILIDADE\", \"HORÁRIO DE INÍCIO DA ATIVIDADE\",\n",
    "    \"HORÁRIO DE FINALIZAÇÃO DA ATIVIDADE\", \"RAZÃO DO CANCELAMENTO\",\n",
    "    \"HORÁRIO DO CANCELAMENTO\", \"HORÁRIO DO DESVIO\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA PTS\", \"HORÁRIO DE LIBERAÇÃO DA PTS\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO\", \"HORÁRIO DE LIBERAÇÃO DO BLOQUEIO\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA LIMPEZA\", \"HORÁRIO DE LIBERAÇÃO DA LIMPEZA\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA OM\", \"HORÁRIO DE RECEBIMENTO DA OM\",\n",
    "    \"HORÁRIO DE SOLICITAÇÃO DA PET\", \"HORÁRIO DE LIBERAÇÃO DA PET\"\n",
    "]\n",
    "\n",
    "# Função para padronizar horas\n",
    "def padronizar_horas(valor):\n",
    "    try:\n",
    "        if isinstance(valor, str) and valor.strip():\n",
    "            # Se o formato for \"HH\", completa para \"HH:00:00\"\n",
    "            if len(valor) == 2 and valor.isdigit():\n",
    "                return f\"{valor}:00:00\"\n",
    "            # Se o formato for \"HH:MM\", completa para \"HH:MM:00\"\n",
    "            elif len(valor) == 5 and \":\" in valor:\n",
    "                return f\"{valor}:00\"\n",
    "            # Se já estiver no formato correto \"HH:MM:SS\", mantém\n",
    "            elif len(valor) == 8 and \":\" in valor:\n",
    "                return valor\n",
    "        # Caso inválido ou vazio, retorna \"00:00:00\"\n",
    "        return \"00:00:00\"\n",
    "    except Exception:\n",
    "        return \"00:00:00\"\n",
    "\n",
    "# Verificar se os arquivos existem\n",
    "if not caminho_arquivo.exists():\n",
    "    print(f\"Erro: O arquivo de entrada '{caminho_arquivo}' não foi encontrado.\")\n",
    "elif not caminho_saida.exists():\n",
    "    print(f\"Erro: O arquivo tratado '{caminho_saida}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar os dois arquivos\n",
    "    df_original = pd.read_csv(caminho_arquivo)\n",
    "    df_tratado = pd.read_csv(caminho_saida)\n",
    "\n",
    "    # Verificar alterações nas colunas de horas\n",
    "    alteracoes = []\n",
    "    for coluna in colunas_horas:\n",
    "        if coluna in df_original.columns and coluna in df_tratado.columns:\n",
    "            for index, (valor_original, valor_tratado) in enumerate(zip(df_original[coluna], df_tratado[coluna])):\n",
    "                valor_padronizado = padronizar_horas(valor_original)\n",
    "                if valor_padronizado != valor_tratado:\n",
    "                    alteracoes.append({\n",
    "                        \"Linha\": index + 1,\n",
    "                        \"Coluna\": coluna,\n",
    "                        \"Valor Original\": valor_original,\n",
    "                        \"Valor Tratado\": valor_tratado,\n",
    "                        \"Esperado\": valor_padronizado\n",
    "                    })\n",
    "\n",
    "    # Exibir ou salvar resultados\n",
    "    if alteracoes:\n",
    "        # Exibição limitada\n",
    "        print(\"Foram encontradas inconsistências nas alterações realizadas:\")\n",
    "        for alteracao in alteracoes[:10]:  # Exibir apenas as primeiras 10 inconsistências\n",
    "            print(f\"Linha {alteracao['Linha']}, Coluna {alteracao['Coluna']}:\")\n",
    "            print(f\" - Valor Original: {alteracao['Valor Original']}\")\n",
    "            print(f\" - Valor Tratado: {alteracao['Valor Tratado']}\")\n",
    "            print(f\" - Esperado: {alteracao['Esperado']}\\n\")\n",
    "        if len(alteracoes) > 10:\n",
    "            print(f\"... e mais {len(alteracoes) - 10} inconsistências.\")\n",
    "\n",
    "        # Salvar relatório de inconsistências\n",
    "        caminho_relatorio = diretorio_atual / \"inconsistencias.csv\"\n",
    "        df_alteracoes = pd.DataFrame(alteracoes)\n",
    "        df_alteracoes.to_csv(caminho_relatorio, index=False)\n",
    "        print(f\"Relatório de inconsistências salvo em: {caminho_relatorio}\")\n",
    "    else:\n",
    "        print(\"Todas as alterações foram feitas corretamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfkCv8Px0gwQ"
   },
   "source": [
    "Tratar Dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1737629737932,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "mjLqFFKU0f3w",
    "outputId": "4e9909b2-e93f-4d34-8dc2-a1442cdf2994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo com medidas padronizadas salvo em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado_medidas.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Definir os caminhos relativos dos arquivos\n",
    "caminho_arquivo = diretorio_atual / \"relatorio_tratado_horas.csv\"\n",
    "caminho_saida = diretorio_atual / \"relatorio_tratado_medidas.csv\"\n",
    "\n",
    "# Lista de colunas de medidas para padronizar\n",
    "colunas_medidas = [\"COMPRIMENTO\", \"LARGURA\", \"ALTURA\"]\n",
    "\n",
    "# Função para padronizar medidas\n",
    "def padronizar_medidas(valor):\n",
    "    try:\n",
    "        # Verifica se o valor está vazio ou não numérico\n",
    "        if pd.isna(valor) or str(valor).strip() == \"\":\n",
    "            return \"0,00\"  # Preenche com 0,00\n",
    "        # Converte para float e depois para o formato desejado\n",
    "        valor_float = float(str(valor).replace(\",\", \".\"))\n",
    "        return f\"{valor_float:,.2f}\".replace(\".\", \",\")  # Padroniza para formato 0,00\n",
    "    except Exception:\n",
    "        return \"0,00\"  # Caso erro, retorna 0,00\n",
    "\n",
    "# Verificar se o arquivo de entrada existe\n",
    "if not caminho_arquivo.exists():\n",
    "    print(f\"Erro: O arquivo de entrada '{caminho_arquivo}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar o arquivo original\n",
    "    df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "    # Padronizar as colunas de medidas\n",
    "    for coluna in colunas_medidas:\n",
    "        if coluna in df.columns:\n",
    "            df[coluna] = df[coluna].apply(padronizar_medidas)\n",
    "\n",
    "    # Salvar o arquivo com as medidas padronizadas\n",
    "    df.to_csv(caminho_saida, index=False)\n",
    "\n",
    "    print(f\"Arquivo com medidas padronizadas salvo em: {caminho_saida}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu2NFlk40mdK"
   },
   "source": [
    "Verificar se dimensões foram tratadas corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1737629742179,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "vTORz0aA0q7o",
    "outputId": "6265d82c-68b2-4dc7-94a2-fe928f68648c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as alterações foram feitas corretamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Definir os caminhos relativos dos arquivos\n",
    "caminho_etapa_4 = diretorio_atual / \"relatorio_tratado.csv\"\n",
    "caminho_etapa_7 = diretorio_atual / \"relatorio_tratado_medidas.csv\"\n",
    "\n",
    "# Lista de colunas de medidas para verificar\n",
    "colunas_medidas = [\"COMPRIMENTO\", \"LARGURA\", \"ALTURA\"]\n",
    "\n",
    "# Função para padronizar medidas\n",
    "def padronizar_medidas(valor):\n",
    "    try:\n",
    "        # Verifica se o valor é um número válido\n",
    "        if isinstance(valor, str) and valor.strip():\n",
    "            # Se o valor for \"NÃ\" ou qualquer outra string não numérica, retorna 0,00\n",
    "            if any(char.isalpha() for char in valor):\n",
    "                return \"0,00\"\n",
    "            # Substitui ponto por vírgula\n",
    "            valor = valor.replace('.', ',')\n",
    "            # Se o valor tiver uma vírgula, verificamos a quantidade de casas decimais\n",
    "            if ',' in valor:\n",
    "                # Caso o valor tenha apenas uma casa decimal, adiciona a segunda casa como \"0\"\n",
    "                if valor.count(',') == 1 and len(valor.split(',')[1]) == 1:\n",
    "                    return f\"{valor}0\"\n",
    "                # Caso o valor já tenha duas casas decimais, retorna o valor como está\n",
    "                elif valor.count(',') == 1 and len(valor.split(',')[1]) == 2:\n",
    "                    return valor\n",
    "                # Caso o valor tenha mais de duas casas decimais, arredonda para 2 casas\n",
    "                else:\n",
    "                    return f\"{valor.split(',')[0]},{valor.split(',')[1][:2]}\"\n",
    "            else:\n",
    "                return f\"{valor},00\"\n",
    "        return \"0,00\"  # Se vazio ou inválido\n",
    "    except Exception:\n",
    "        return \"0,00\"  # Retorna \"0,00\" em caso de erro\n",
    "\n",
    "# Verificar se o arquivo de entrada da etapa 4 existe\n",
    "if not caminho_etapa_4.exists():\n",
    "    print(f\"Erro: O arquivo de entrada '{caminho_etapa_4}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar os dois arquivos\n",
    "    df_etapa_4 = pd.read_csv(caminho_etapa_4)\n",
    "    df_etapa_7 = pd.read_csv(caminho_etapa_7)\n",
    "\n",
    "    # Verificar alterações nas colunas de medidas\n",
    "    alteracoes = []\n",
    "    for coluna in colunas_medidas:\n",
    "        if coluna in df_etapa_4.columns and coluna in df_etapa_7.columns:\n",
    "            for index, (valor_etapa_4, valor_etapa_7) in enumerate(zip(df_etapa_4[coluna], df_etapa_7[coluna])):\n",
    "                valor_padronizado = padronizar_medidas(valor_etapa_4)\n",
    "                # Comparar valor tratado com o valor padronizado\n",
    "                if valor_padronizado != valor_etapa_7:\n",
    "                    alteracoes.append({\n",
    "                        \"Linha\": index + 1,\n",
    "                        \"Coluna\": coluna,\n",
    "                        \"Valor Original\": valor_etapa_4,\n",
    "                        \"Valor Tratado\": valor_etapa_7,\n",
    "                        \"Esperado\": valor_padronizado\n",
    "                    })\n",
    "\n",
    "    # Exibir resultados\n",
    "    if alteracoes:\n",
    "        print(\"Foram encontradas inconsistências nas alterações realizadas:\")\n",
    "        for alteracao in alteracoes:\n",
    "            print(f\"Linha {alteracao['Linha']}, Coluna {alteracao['Coluna']}:\")\n",
    "            print(f\" - Valor Original: {alteracao['Valor Original']}\")\n",
    "            print(f\" - Valor Tratado: {alteracao['Valor Tratado']}\")\n",
    "            print(f\" - Esperado: {alteracao['Esperado']}\\n\")\n",
    "    else:\n",
    "        print(\"Todas as alterações foram feitas corretamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRmhCwsb1JWI"
   },
   "source": [
    "Padronizar valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1737629746444,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "GvfcSEwu1Lkd",
    "outputId": "a78aa100-1fdf-437a-87b5-d410570bd131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo tratado e salvo em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado_qtd.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Definir os caminhos relativos dos arquivos\n",
    "arquivo_entrada = diretorio_atual / \"relatorio_tratado_medidas.csv\"\n",
    "arquivo_saida = diretorio_atual / \"relatorio_tratado_qtd.csv\"\n",
    "\n",
    "# Lista de colunas para verificar\n",
    "colunas_tratamento = [\"QTD PESSOAS\", \"QUANTIDADE DE ANDAIMES\"]\n",
    "\n",
    "# Função para padronizar os valores\n",
    "def padronizar_valores(valor):\n",
    "    try:\n",
    "        # Verifica se é NaN ou vazio\n",
    "        if pd.isna(valor) or str(valor).strip() == \"\":\n",
    "            return \"0,00\"\n",
    "        # Verifica se é texto\n",
    "        if isinstance(valor, str):\n",
    "            valor = valor.strip().lower()\n",
    "            if not valor.replace('.', '').replace(',', '').isdigit():\n",
    "                return \"0,00\"\n",
    "        # Conversão para float\n",
    "        valor = float(valor)\n",
    "        if valor in [1, 1.0, 1.00]:\n",
    "            return \"1,00\"\n",
    "        elif valor in [3, 3.0, 3.00]:\n",
    "            return \"3,00\"\n",
    "        elif valor in [10, 10.0, 10.00]:\n",
    "            return \"10,00\"\n",
    "        elif valor in [0, 0.0, 0.00]:\n",
    "            return \"0,00\"\n",
    "        # Retorna valores no formato esperado\n",
    "        return f\"{valor:.2f}\".replace('.', ',')\n",
    "    except Exception:\n",
    "        return \"0,00\"  # Retorna \"0,00\" em caso de erro\n",
    "\n",
    "# Verificar se o arquivo de entrada existe\n",
    "if not arquivo_entrada.exists():\n",
    "    print(f\"Erro: O arquivo de entrada '{arquivo_entrada}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar o arquivo de entrada\n",
    "    try:\n",
    "        df_entrada = pd.read_csv(arquivo_entrada)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo de entrada: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Criar uma cópia do DataFrame para saída\n",
    "    df_saida = df_entrada.copy()\n",
    "\n",
    "    # Verificar e tratar as colunas\n",
    "    for coluna in colunas_tratamento:\n",
    "        if coluna in df_entrada.columns:\n",
    "            # Padronizar valores na coluna\n",
    "            df_saida[coluna] = df_entrada[coluna].apply(padronizar_valores)\n",
    "        else:\n",
    "            print(f\"Coluna {coluna} não encontrada no arquivo de entrada.\")\n",
    "\n",
    "    # Salvar o arquivo tratado\n",
    "    try:\n",
    "        df_saida.to_csv(arquivo_saida, index=False)\n",
    "        print(f\"Arquivo tratado e salvo em: {arquivo_saida}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o arquivo de saída: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkRdnaQV1j_q"
   },
   "source": [
    "Verificar se tratamento foi executado corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1737629749363,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "R_VZc7CJ1m7s",
    "outputId": "4b225913-8888-422f-8034-71049d7b7002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhuma inconsistência foi encontrada entre os arquivos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Definir os caminhos relativos dos arquivos\n",
    "arquivo_original = diretorio_atual / \"relatorio_tratado.csv\"\n",
    "arquivo_tratado = diretorio_atual / \"relatorio_tratado_qtd.csv\"\n",
    "\n",
    "# Lista de colunas para verificar\n",
    "colunas_tratamento = [\"QTD PESSOAS\", \"QUANTIDADE DE ANDAIMES\"]\n",
    "\n",
    "# Função para padronizar os valores\n",
    "def padronizar_valores(valor):\n",
    "    try:\n",
    "        # Verifica se é NaN ou vazio\n",
    "        if pd.isna(valor) or str(valor).strip() == \"\":\n",
    "            return \"0,00\"\n",
    "        # Verifica se é texto\n",
    "        if isinstance(valor, str):\n",
    "            valor = valor.strip().lower()\n",
    "            if not valor.replace('.', '').replace(',', '').isdigit():\n",
    "                return \"0,00\"\n",
    "        # Conversão para float, se aplicável\n",
    "        valor = float(valor)\n",
    "        if valor == 1 or valor == 1.0 or valor == 1.00:\n",
    "            return \"1,00\"\n",
    "        elif valor == 3 or valor == 3.0 or valor == 3.00:\n",
    "            return \"3,00\"\n",
    "        elif valor == 10 or valor == 10.0 or valor == 10.00:\n",
    "            return \"10,00\"\n",
    "        elif valor == 0 or valor == 0.0 or valor == 0.00:\n",
    "            return \"0,00\"\n",
    "        # Retorna valores no formato esperado\n",
    "        return f\"{valor:.2f}\".replace('.', ',')\n",
    "    except Exception:\n",
    "        return \"0,00\"  # Retorna \"0,00\" em caso de erro\n",
    "\n",
    "# Verificar se os arquivos existem\n",
    "if not arquivo_original.exists():\n",
    "    print(f\"Erro: O arquivo original '{arquivo_original}' não foi encontrado.\")\n",
    "else:\n",
    "    if not arquivo_tratado.exists():\n",
    "        print(f\"Erro: O arquivo tratado '{arquivo_tratado}' não foi encontrado.\")\n",
    "    else:\n",
    "        # Carregar os arquivos original e tratado\n",
    "        try:\n",
    "            df_original = pd.read_csv(arquivo_original)\n",
    "            df_tratado = pd.read_csv(arquivo_tratado)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar os arquivos: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Função para verificar se o valor foi alterado indevidamente\n",
    "        def verificar_valor_tratado(valor_original, valor_tratado):\n",
    "            # Padronizar o valor original para o formato esperado\n",
    "            valor_esperado = padronizar_valores(valor_original)\n",
    "            # Comparar os valores\n",
    "            if str(valor_esperado).replace(',', '.').strip() != str(valor_tratado).replace(',', '.').strip():\n",
    "                return False, valor_esperado\n",
    "            return True, valor_esperado\n",
    "\n",
    "        # Verificar inconsistências\n",
    "        inconsistencias = []\n",
    "        for coluna in colunas_tratamento:\n",
    "            if coluna in df_original.columns and coluna in df_tratado.columns:\n",
    "                for index, (valor_original, valor_tratado) in enumerate(zip(df_original[coluna], df_tratado[coluna])):\n",
    "                    valido, valor_esperado = verificar_valor_tratado(valor_original, valor_tratado)\n",
    "                    if not valido:\n",
    "                        inconsistencias.append({\n",
    "                            \"Linha\": index + 1,\n",
    "                            \"Coluna\": coluna,\n",
    "                            \"Valor Original\": valor_original,\n",
    "                            \"Valor Tratado\": valor_tratado,\n",
    "                            \"Esperado\": valor_esperado\n",
    "                        })\n",
    "\n",
    "        # Exibir resultados\n",
    "        if inconsistencias:\n",
    "            print(\"Foram encontradas inconsistências entre os arquivos:\")\n",
    "            for inc in inconsistencias:\n",
    "                print(f\"Linha {inc['Linha']}, Coluna {inc['Coluna']}:\")\n",
    "                print(f\" - Valor Original: {inc['Valor Original']}\")\n",
    "                print(f\" - Valor Tratado: {inc['Valor Tratado']}\")\n",
    "                print(f\" - Esperado: {inc['Esperado']}\\n\")\n",
    "        else:\n",
    "            print(\"Nenhuma inconsistência foi encontrada entre os arquivos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6fuFtPu14q1"
   },
   "source": [
    "Tratar Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1737629753408,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "VUztlmPu150N",
    "outputId": "e30a57d5-570b-4a77-ac58-13e15d4f4a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datas corrigidas e arquivo atualizado com sucesso! Arquivo salvo em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado_datas.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Caminhos relativos dos arquivos de entrada e saída\n",
    "arquivo_entrada = diretorio_atual / \"relatorio_tratado_qtd.csv\"\n",
    "arquivo_saida = diretorio_atual / \"relatorio_tratado_datas.csv\"\n",
    "\n",
    "# Função para padronizar as datas\n",
    "def padronizar_data(data):\n",
    "    try:\n",
    "        # Remover espaços extras e barras duplicadas\n",
    "        data = str(data).strip()\n",
    "        # Remove qualquer espaço antes e depois das barras\n",
    "        data = data.replace(\" //\", \"/\").replace(\"//\", \"/\").replace(\"/ \", \"/\")\n",
    "        data = data.replace(\" \", \"\")  # Remover qualquer espaço extra em toda a data\n",
    "\n",
    "        # Verificar se a data contém o ano (ex.: \"03/01/2024\" ou \"03/01/25\")\n",
    "        if len(data.split(\"/\")) == 3:  # Se tem 3 partes (dia/mês/ano)\n",
    "            dia, mes, ano = data.split(\"/\")\n",
    "            # Corrigir anos com 2 dígitos, como \"25\" para \"2025\"\n",
    "            if len(ano) == 2:\n",
    "                ano = \"20\" + ano\n",
    "            # Padronizar para o formato DD/MM/YYYY\n",
    "            return datetime.strptime(f\"{dia}/{mes}/{ano}\", \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        # Corrigir datas com apenas dia e mês (como \"06/12\")\n",
    "        if len(data.split(\"/\")) == 2:\n",
    "            data = data + \"/\" + str(datetime.now().year)  # Adicionar o ano atual\n",
    "            return datetime.strptime(data, \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        # Caso o valor não seja uma data válida, retorna o valor original\n",
    "        return data\n",
    "\n",
    "# Verificar se o arquivo de entrada existe\n",
    "if not arquivo_entrada.exists():\n",
    "    print(f\"Erro: O arquivo de entrada '{arquivo_entrada}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar o arquivo de entrada\n",
    "    try:\n",
    "        df = pd.read_csv(arquivo_entrada)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo '{arquivo_entrada}': {e}\")\n",
    "        raise\n",
    "\n",
    "    # Verificar a coluna de datas e padronizar\n",
    "    if 'DATA DE EXECUÇÃO' in df.columns:\n",
    "        for index, data in enumerate(df['DATA DE EXECUÇÃO']):\n",
    "            data_padronizada = padronizar_data(data)\n",
    "            # Se a data padronizada for diferente da original, vamos atualizar\n",
    "            if data_padronizada != str(data).strip():\n",
    "                df.at[index, 'DATA DE EXECUÇÃO'] = data_padronizada\n",
    "\n",
    "    # Corrigir datas de 2024 que são inconsistentes\n",
    "    for index, data in enumerate(df['DATA DE EXECUÇÃO']):\n",
    "        try:\n",
    "            data_formatada = datetime.strptime(data, \"%d/%m/%Y\")\n",
    "            # Corrigir datas muito antigas, por exemplo, 03/01/2024 quando deveriam ser de 2025\n",
    "            if data_formatada.year == 2024 and data_formatada < datetime(2025, 1, 1):\n",
    "                df.at[index, 'DATA DE EXECUÇÃO'] = (data_formatada.replace(year=2025)).strftime(\"%d/%m/%Y\")\n",
    "        except Exception:\n",
    "            continue  # Se a data não estiver no formato esperado, ignore a linha\n",
    "\n",
    "    # Verificar se o arquivo de saída pode ser salvo\n",
    "    if not arquivo_saida.parent.exists():\n",
    "        print(f\"Erro: O diretório de saída '{arquivo_saida.parent}' não existe.\")\n",
    "    else:\n",
    "        # Salvar o arquivo corrigido\n",
    "        try:\n",
    "            df.to_csv(arquivo_saida, index=False)\n",
    "            print(f\"Datas corrigidas e arquivo atualizado com sucesso! Arquivo salvo em: {arquivo_saida}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao salvar o arquivo '{arquivo_saida}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6CdRP_Q2Joa"
   },
   "source": [
    "Verificar datas tratadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1737629758272,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "0o3Wcp8Q2LWb",
    "outputId": "2ae67c3e-cc52-4479-8be1-f111bf116048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as datas foram tratadas corretamente!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Caminhos relativos dos arquivos\n",
    "caminho_arquivo_original = diretorio_atual / \"relatorio_tratado_qtd.csv\"\n",
    "caminho_arquivo_tratado = diretorio_atual / \"relatorio_tratado_datas.csv\"\n",
    "\n",
    "# Função para verificar a padronização da data com base nas regras\n",
    "def verificar_data(data):\n",
    "    try:\n",
    "        data = str(data).strip()\n",
    "        data = data.replace(\" //\", \"/\").replace(\"//\", \"/\").replace(\"/ \", \"/\").replace(\" \", \"\")\n",
    "\n",
    "        if len(data.split(\"/\")) == 3:\n",
    "            dia, mes, ano = data.split(\"/\")\n",
    "            if len(ano) == 2:\n",
    "                ano = \"20\" + ano\n",
    "            # Garantir zeros à esquerda\n",
    "            dia = dia.zfill(2)\n",
    "            mes = mes.zfill(2)\n",
    "            return f\"{dia}/{mes}/{ano}\"\n",
    "\n",
    "        if len(data.split(\"/\")) == 2:\n",
    "            dia, mes = data.split(\"/\")\n",
    "            # Garantir zeros à esquerda e adicionar o ano atual\n",
    "            dia = dia.zfill(2)\n",
    "            mes = mes.zfill(2)\n",
    "            return f\"{dia}/{mes}/{datetime.now().year}\"\n",
    "\n",
    "        return data\n",
    "    except Exception:\n",
    "        return data\n",
    "\n",
    "# Verificar se os arquivos de entrada existem\n",
    "if not caminho_arquivo_original.exists():\n",
    "    print(f\"Erro: O arquivo original '{caminho_arquivo_original}' não foi encontrado.\")\n",
    "elif not caminho_arquivo_tratado.exists():\n",
    "    print(f\"Erro: O arquivo tratado '{caminho_arquivo_tratado}' não foi encontrado.\")\n",
    "else:\n",
    "    # Carregar os arquivos\n",
    "    try:\n",
    "        df_original = pd.read_csv(caminho_arquivo_original)\n",
    "        df_tratado = pd.read_csv(caminho_arquivo_tratado)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar os arquivos: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Verificar inconsistências\n",
    "    if 'DATA DE EXECUÇÃO' in df_original.columns and 'DATA DE EXECUÇÃO' in df_tratado.columns:\n",
    "        inconsistencias = []\n",
    "\n",
    "        for index, (data_original, data_tratada) in enumerate(zip(df_original['DATA DE EXECUÇÃO'], df_tratado['DATA DE EXECUÇÃO'])):\n",
    "            # Determinar o valor esperado sem realizar modificações no dado original\n",
    "            esperado = verificar_data(data_original)\n",
    "\n",
    "            # Ajuste para anos inconsistentes\n",
    "            try:\n",
    "                data_formatada = datetime.strptime(esperado, \"%d/%m/%Y\")\n",
    "                if data_formatada.year == 2024 and data_formatada < datetime(2025, 1, 1):\n",
    "                    esperado = data_formatada.replace(year=2025).strftime(\"%d/%m/%Y\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Verificar se o valor tratado corresponde ao esperado\n",
    "            if esperado != data_tratada:\n",
    "                inconsistencias.append({\n",
    "                    \"Linha\": index + 1,\n",
    "                    \"Valor Original\": data_original,\n",
    "                    \"Valor Tratado\": data_tratada,\n",
    "                    \"Esperado\": esperado\n",
    "                })\n",
    "\n",
    "        # Exibir inconsistências\n",
    "        if inconsistencias:\n",
    "            print(\"Foram encontradas inconsistências:\")\n",
    "            for inconsistencia in inconsistencias:\n",
    "                print(f\"Linha {inconsistencia['Linha']}:\")\n",
    "                print(f\" - Valor Original: {inconsistencia['Valor Original']}\")\n",
    "                print(f\" - Valor Tratado: {inconsistencia['Valor Tratado']}\")\n",
    "                print(f\" - Esperado: {inconsistencia['Esperado']}\\n\")\n",
    "        else:\n",
    "            print(\"Todas as datas foram tratadas corretamente!\")\n",
    "    else:\n",
    "        print(\"Coluna 'DATA DE EXECUÇÃO' não encontrada em um dos arquivos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwrtU_Jn2kzZ"
   },
   "source": [
    "Transformar para caixa alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1737629762318,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "LQLPVmmq2msR",
    "outputId": "66b18c16-0533-4ebe-b039-30c752eeb5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo gerado com sucesso em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado_caixa_alta.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrador\\AppData\\Local\\Temp\\ipykernel_19536\\3360258727.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Caminhos relativos para o arquivo de entrada e saída\n",
    "arquivo_saida = diretorio_atual / \"relatorio_tratado_datas.csv\"\n",
    "arquivo_caixa_alta = diretorio_atual / \"relatorio_tratado_caixa_alta.csv\"\n",
    "\n",
    "# Verificar se o arquivo de entrada existe\n",
    "if not arquivo_saida.exists():\n",
    "    print(f\"Erro: O arquivo original '{arquivo_saida}' não foi encontrado.\")\n",
    "else:\n",
    "    try:\n",
    "        # Carregar o arquivo original\n",
    "        df = pd.read_csv(arquivo_saida)\n",
    "\n",
    "        # Converter todas as colunas de texto para caixa alta\n",
    "        df = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "        # Salvar o novo arquivo com os dados em caixa alta\n",
    "        df.to_csv(arquivo_caixa_alta, index=False)\n",
    "\n",
    "        print(f\"Arquivo gerado com sucesso em: {arquivo_caixa_alta}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgG7iEOY24p-"
   },
   "source": [
    "Verificar se foi devidamente tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1737629771413,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "FGtWhInc24Io",
    "outputId": "114cb885-70b6-4794-fc40-7186f5185481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel criado com sucesso em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Determinar o diretório de trabalho atual\n",
    "diretorio_atual = Path.cwd()\n",
    "\n",
    "# Caminhos relativos para o arquivo CSV de entrada e o arquivo Excel de saída\n",
    "arquivo_csv = diretorio_atual / \"relatorio_tratado_caixa_alta.csv\"\n",
    "arquivo_excel = diretorio_atual / \"relatorio_tratado.xlsx\"\n",
    "\n",
    "# Verificar se o arquivo CSV existe\n",
    "if not arquivo_csv.exists():\n",
    "    print(f\"Erro: O arquivo '{arquivo_csv}' não foi encontrado.\")\n",
    "else:\n",
    "    try:\n",
    "        # Ler o arquivo CSV e garantir que a coluna ORDEM seja tratada como string\n",
    "        df = pd.read_csv(arquivo_csv, dtype={'ORDEM': str})\n",
    "\n",
    "        # Salvar para Excel sem modificar os valores\n",
    "        df.to_excel(arquivo_excel, index=False, engine='openpyxl')\n",
    "\n",
    "        print(f\"Arquivo Excel criado com sucesso em: {arquivo_excel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4yADH2F269a"
   },
   "source": [
    "Criar COLUNA de RETORNO DA EXECUÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1737630422691,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "JIcHkm6u28nv",
    "outputId": "4018c5e3-c4e4-4524-c5a7-86203929aef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso.\n",
      "Primeiras linhas do arquivo:\n",
      "  DATA DE EXECUÇÃO              STATUS DA EXECUÇÃO STATUS DO PLANEJAMENTO  \\\n",
      "0       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "1       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "2       23/01/2025  MONTAGEM DE ANDAIME FINALIZADA             PROGRAMADO   \n",
      "3       23/01/2025  MONTAGEM DE ANDAIME FINALIZADO              CORRETIVA   \n",
      "4       23/01/2025                         MONTADO                    NaN   \n",
      "\n",
      "            TAG         ORDEM  \\\n",
      "0         2PE03  202500155907   \n",
      "1         2PE01  202500155806   \n",
      "2  TC-6042-09TC  202500258690   \n",
      "3       TC-6015  202500399129   \n",
      "4        TC5007  202405254103   \n",
      "\n",
      "                                           DESCRIÇÃO QTD PESSOAS  \\\n",
      "0                                                NaN        3,00   \n",
      "1                                                NaN        3,00   \n",
      "2  MONTAGEM DE ANDAIME PARA VOCALIZAÇÃO ACESSAR O...        4,00   \n",
      "3  FORRAMENTO DA TC-6015 PARA VULCANIZAÇÃO DÁ REP...        4,00   \n",
      "4                                       MONT/DESMONT        4,00   \n",
      "\n",
      "    TIPO DE ANDAIME QUANTIDADE DE ANDAIMES COMPRIMENTO  ...  \\\n",
      "0         PASSARELA                   1,00        3,20  ...   \n",
      "1             TORRE                   1,00        2,50  ...   \n",
      "2  ESCADA DE ACESSO                   1,00        1,90  ...   \n",
      "3        FORRAMENTO                   1,00        2,00  ...   \n",
      "4           SIMPLES                   1,00        2,00  ...   \n",
      "\n",
      "  HORÁRIO DE SOLICITAÇÃO DA PTS HORÁRIO DE LIBERAÇÃO DA PTS  \\\n",
      "0                      17:00:00                    17:10:00   \n",
      "1                      19:00:00                    19:40:00   \n",
      "2                      09:01:00                    09:05:00   \n",
      "3                      00:00:00                    00:00:00   \n",
      "4                      09:00:00                    09:40:00   \n",
      "\n",
      "  HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO HORÁRIO DE LIBERAÇÃO DO BLOQUEIO  \\\n",
      "0                           00:00:00                         00:00:00   \n",
      "1                           00:00:00                         00:00:00   \n",
      "2                           00:00:00                         00:00:00   \n",
      "3                           00:00:00                         00:00:00   \n",
      "4                           09:00:00                         09:30:00   \n",
      "\n",
      "  HORÁRIO DE SOLICITAÇÃO DA LIMPEZA HORÁRIO DE LIBERAÇÃO DA LIMPEZA  \\\n",
      "0                          00:00:00                        00:00:00   \n",
      "1                          00:00:00                        00:00:00   \n",
      "2                          00:00:00                        00:00:00   \n",
      "3                          00:00:00                        00:00:00   \n",
      "4                          00:00:00                        00:00:00   \n",
      "\n",
      "  HORÁRIO DE SOLICITAÇÃO DA OM HORÁRIO DE RECEBIMENTO DA OM  \\\n",
      "0                     00:00:00                     00:00:00   \n",
      "1                     00:00:00                     00:00:00   \n",
      "2                     00:00:00                     00:00:00   \n",
      "3                     00:00:00                     00:00:00   \n",
      "4                     00:00:00                     00:00:00   \n",
      "\n",
      "  HORÁRIO DE SOLICITAÇÃO DA PET HORÁRIO DE LIBERAÇÃO DA PET  \n",
      "0                      00:00:00                    00:00:00  \n",
      "1                      00:00:00                    00:00:00  \n",
      "2                      00:00:00                    00:00:00  \n",
      "3                      00:00:00                    00:00:00  \n",
      "4                      00:00:00                    00:00:00  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Primeiras linhas após adicionar a coluna 'RETORNO DA EXECUÇÃO':\n",
      "  DATA DE EXECUÇÃO              STATUS DA EXECUÇÃO STATUS DO PLANEJAMENTO  \\\n",
      "0       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "1       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "2       23/01/2025  MONTAGEM DE ANDAIME FINALIZADA             PROGRAMADO   \n",
      "3       23/01/2025  MONTAGEM DE ANDAIME FINALIZADO              CORRETIVA   \n",
      "4       23/01/2025                         MONTADO                    NaN   \n",
      "\n",
      "            TAG         ORDEM  \\\n",
      "0         2PE03  202500155907   \n",
      "1         2PE01  202500155806   \n",
      "2  TC-6042-09TC  202500258690   \n",
      "3       TC-6015  202500399129   \n",
      "4        TC5007  202405254103   \n",
      "\n",
      "                                           DESCRIÇÃO QTD PESSOAS  \\\n",
      "0                                                NaN        3,00   \n",
      "1                                                NaN        3,00   \n",
      "2  MONTAGEM DE ANDAIME PARA VOCALIZAÇÃO ACESSAR O...        4,00   \n",
      "3  FORRAMENTO DA TC-6015 PARA VULCANIZAÇÃO DÁ REP...        4,00   \n",
      "4                                       MONT/DESMONT        4,00   \n",
      "\n",
      "    TIPO DE ANDAIME QUANTIDADE DE ANDAIMES COMPRIMENTO  ...  \\\n",
      "0         PASSARELA                   1,00        3,20  ...   \n",
      "1             TORRE                   1,00        2,50  ...   \n",
      "2  ESCADA DE ACESSO                   1,00        1,90  ...   \n",
      "3        FORRAMENTO                   1,00        2,00  ...   \n",
      "4           SIMPLES                   1,00        2,00  ...   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PTS HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO  \\\n",
      "0                    17:10:00                           00:00:00   \n",
      "1                    19:40:00                           00:00:00   \n",
      "2                    09:05:00                           00:00:00   \n",
      "3                    00:00:00                           00:00:00   \n",
      "4                    09:40:00                           09:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DO BLOQUEIO HORÁRIO DE SOLICITAÇÃO DA LIMPEZA  \\\n",
      "0                         00:00:00                          00:00:00   \n",
      "1                         00:00:00                          00:00:00   \n",
      "2                         00:00:00                          00:00:00   \n",
      "3                         00:00:00                          00:00:00   \n",
      "4                         09:30:00                          00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA LIMPEZA HORÁRIO DE SOLICITAÇÃO DA OM  \\\n",
      "0                        00:00:00                     00:00:00   \n",
      "1                        00:00:00                     00:00:00   \n",
      "2                        00:00:00                     00:00:00   \n",
      "3                        00:00:00                     00:00:00   \n",
      "4                        00:00:00                     00:00:00   \n",
      "\n",
      "  HORÁRIO DE RECEBIMENTO DA OM HORÁRIO DE SOLICITAÇÃO DA PET  \\\n",
      "0                     00:00:00                      00:00:00   \n",
      "1                     00:00:00                      00:00:00   \n",
      "2                     00:00:00                      00:00:00   \n",
      "3                     00:00:00                      00:00:00   \n",
      "4                     00:00:00                      00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PET RETORNO DA EXECUÇÃO  \n",
      "0                    00:00:00           EXECUTADO  \n",
      "1                    00:00:00           EXECUTADO  \n",
      "2                    00:00:00           EXECUTADO  \n",
      "3                    00:00:00           EXECUTADO  \n",
      "4                    00:00:00           EXECUTADO  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Coluna 'RETORNO DA EXECUÇÃO' adicionada com sucesso no arquivo: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Função para criar a coluna 'RETORNO DA EXECUÇÃO'\n",
    "def criar_coluna_retorno(arquivo_excel):\n",
    "    # Verificar se o arquivo Excel existe\n",
    "    if not arquivo_excel.exists():\n",
    "        print(f\"Erro: O arquivo '{arquivo_excel}' não foi encontrado.\")\n",
    "        return\n",
    "\n",
    "    # Carregar o arquivo Excel\n",
    "    try:\n",
    "        df = pd.read_excel(arquivo_excel)\n",
    "        print(\"Arquivo carregado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo: {e}\")\n",
    "        return\n",
    "\n",
    "    # Exibir as primeiras linhas para depuração\n",
    "    print(\"Primeiras linhas do arquivo:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Verificar se a coluna 'STATUS DA EXECUÇÃO' existe, removendo espaços extras\n",
    "    if 'STATUS DA EXECUÇÃO' not in df.columns:\n",
    "        print(\"A coluna 'STATUS DA EXECUÇÃO' não foi encontrada no arquivo. Verificando se há espaços extras...\")\n",
    "        df.columns = df.columns.str.strip()  # Remover espaços extras nos nomes das colunas\n",
    "        if 'STATUS DA EXECUÇÃO' not in df.columns:\n",
    "            print(\"A coluna 'STATUS DA EXECUÇÃO' ainda não foi encontrada após remoção de espaços.\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Espaços extras removidos. Coluna 'STATUS DA EXECUÇÃO' encontrada.\")\n",
    "\n",
    "    # Definir as palavras relacionadas a \"CANCELADO\"\n",
    "    cancelado_palavras = [\"CANCELADO\", \"CANCELADA\", \"CANCELL\", \"CANCEL\", \"CANCELO\"]\n",
    "\n",
    "    # Definir as palavras relacionadas a \"EXECUTADO\"\n",
    "    executado_palavras = [\"MONTADO\", \"DESMONTADO\", \"ADEQUAÇÃO\", \"EXECUTADO\", \"MONTAGEM\", \"DESMONTA\"]\n",
    "\n",
    "    # Criar a nova coluna 'RETORNO DA EXECUÇÃO' com valores default vazios\n",
    "    df['RETORNO DA EXECUÇÃO'] = \"\"\n",
    "\n",
    "    # Verificar o campo 'STATUS DA EXECUÇÃO' e atribuir valores à nova coluna\n",
    "    for index, row in df.iterrows():\n",
    "        status_execucao = str(row['STATUS DA EXECUÇÃO']).upper()  # Converter para maiúsculas para comparação\n",
    "\n",
    "        # Verificar se o status está relacionado a \"CANCELADO\"\n",
    "        if any(palavra in status_execucao for palavra in cancelado_palavras):\n",
    "            df.at[index, 'RETORNO DA EXECUÇÃO'] = \"CANCELADO\"\n",
    "\n",
    "        # Verificar se o status está relacionado a \"EXECUTADO\"\n",
    "        elif any(palavra in status_execucao for palavra in executado_palavras):\n",
    "            df.at[index, 'RETORNO DA EXECUÇÃO'] = \"EXECUTADO\"\n",
    "\n",
    "    # Exibir as primeiras linhas após adicionar a coluna\n",
    "    print(\"Primeiras linhas após adicionar a coluna 'RETORNO DA EXECUÇÃO':\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Salvar o arquivo modificado no mesmo local\n",
    "    try:\n",
    "        df.to_excel(arquivo_excel, index=False, engine='openpyxl')\n",
    "        print(f\"Coluna 'RETORNO DA EXECUÇÃO' adicionada com sucesso no arquivo: {arquivo_excel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o arquivo: {e}\")\n",
    "\n",
    "\n",
    "# Determinar o diretório de trabalho atual e o caminho relativo do arquivo\n",
    "diretorio_atual = Path.cwd()\n",
    "arquivo_excel = diretorio_atual / \"relatorio_tratado.xlsx\"\n",
    "\n",
    "# Chamar a função para processar o arquivo\n",
    "criar_coluna_retorno(arquivo_excel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzANwa-1DBtd"
   },
   "source": [
    "REORGANIZAR COLUNAS RETORNO DA EXECUÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1737630439535,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "HaOZCdVuDGPh",
    "outputId": "c990cdeb-d43b-49f8-8e10-dc16e8263162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso.\n",
      "Primeiras linhas do arquivo:\n",
      "  DATA DE EXECUÇÃO              STATUS DA EXECUÇÃO STATUS DO PLANEJAMENTO  \\\n",
      "0       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "1       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "2       23/01/2025  MONTAGEM DE ANDAIME FINALIZADA             PROGRAMADO   \n",
      "3       23/01/2025  MONTAGEM DE ANDAIME FINALIZADO              CORRETIVA   \n",
      "4       23/01/2025                         MONTADO                    NaN   \n",
      "\n",
      "            TAG         ORDEM  \\\n",
      "0         2PE03  202500155907   \n",
      "1         2PE01  202500155806   \n",
      "2  TC-6042-09TC  202500258690   \n",
      "3       TC-6015  202500399129   \n",
      "4        TC5007  202405254103   \n",
      "\n",
      "                                           DESCRIÇÃO QTD PESSOAS  \\\n",
      "0                                                NaN        3,00   \n",
      "1                                                NaN        3,00   \n",
      "2  MONTAGEM DE ANDAIME PARA VOCALIZAÇÃO ACESSAR O...        4,00   \n",
      "3  FORRAMENTO DA TC-6015 PARA VULCANIZAÇÃO DÁ REP...        4,00   \n",
      "4                                       MONT/DESMONT        4,00   \n",
      "\n",
      "    TIPO DE ANDAIME QUANTIDADE DE ANDAIMES COMPRIMENTO  ...  \\\n",
      "0         PASSARELA                   1,00        3,20  ...   \n",
      "1             TORRE                   1,00        2,50  ...   \n",
      "2  ESCADA DE ACESSO                   1,00        1,90  ...   \n",
      "3        FORRAMENTO                   1,00        2,00  ...   \n",
      "4           SIMPLES                   1,00        2,00  ...   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PTS HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO  \\\n",
      "0                    17:10:00                           00:00:00   \n",
      "1                    19:40:00                           00:00:00   \n",
      "2                    09:05:00                           00:00:00   \n",
      "3                    00:00:00                           00:00:00   \n",
      "4                    09:40:00                           09:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DO BLOQUEIO HORÁRIO DE SOLICITAÇÃO DA LIMPEZA  \\\n",
      "0                         00:00:00                          00:00:00   \n",
      "1                         00:00:00                          00:00:00   \n",
      "2                         00:00:00                          00:00:00   \n",
      "3                         00:00:00                          00:00:00   \n",
      "4                         09:30:00                          00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA LIMPEZA HORÁRIO DE SOLICITAÇÃO DA OM  \\\n",
      "0                        00:00:00                     00:00:00   \n",
      "1                        00:00:00                     00:00:00   \n",
      "2                        00:00:00                     00:00:00   \n",
      "3                        00:00:00                     00:00:00   \n",
      "4                        00:00:00                     00:00:00   \n",
      "\n",
      "  HORÁRIO DE RECEBIMENTO DA OM HORÁRIO DE SOLICITAÇÃO DA PET  \\\n",
      "0                     00:00:00                      00:00:00   \n",
      "1                     00:00:00                      00:00:00   \n",
      "2                     00:00:00                      00:00:00   \n",
      "3                     00:00:00                      00:00:00   \n",
      "4                     00:00:00                      00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PET RETORNO DA EXECUÇÃO  \n",
      "0                    00:00:00           EXECUTADO  \n",
      "1                    00:00:00           EXECUTADO  \n",
      "2                    00:00:00           EXECUTADO  \n",
      "3                    00:00:00           EXECUTADO  \n",
      "4                    00:00:00           EXECUTADO  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Primeiras linhas após reorganizar as colunas:\n",
      "  DATA DE EXECUÇÃO              STATUS DA EXECUÇÃO STATUS DO PLANEJAMENTO  \\\n",
      "0       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "1       22/01/2025                     DESMONTAGEM             PROGRAMADO   \n",
      "2       23/01/2025  MONTAGEM DE ANDAIME FINALIZADA             PROGRAMADO   \n",
      "3       23/01/2025  MONTAGEM DE ANDAIME FINALIZADO              CORRETIVA   \n",
      "4       23/01/2025                         MONTADO                    NaN   \n",
      "\n",
      "  RETORNO DA EXECUÇÃO           TAG         ORDEM  \\\n",
      "0           EXECUTADO         2PE03  202500155907   \n",
      "1           EXECUTADO         2PE01  202500155806   \n",
      "2           EXECUTADO  TC-6042-09TC  202500258690   \n",
      "3           EXECUTADO       TC-6015  202500399129   \n",
      "4           EXECUTADO        TC5007  202405254103   \n",
      "\n",
      "                                           DESCRIÇÃO QTD PESSOAS  \\\n",
      "0                                                NaN        3,00   \n",
      "1                                                NaN        3,00   \n",
      "2  MONTAGEM DE ANDAIME PARA VOCALIZAÇÃO ACESSAR O...        4,00   \n",
      "3  FORRAMENTO DA TC-6015 PARA VULCANIZAÇÃO DÁ REP...        4,00   \n",
      "4                                       MONT/DESMONT        4,00   \n",
      "\n",
      "    TIPO DE ANDAIME QUANTIDADE DE ANDAIMES  ... HORÁRIO DE SOLICITAÇÃO DA PTS  \\\n",
      "0         PASSARELA                   1,00  ...                      17:00:00   \n",
      "1             TORRE                   1,00  ...                      19:00:00   \n",
      "2  ESCADA DE ACESSO                   1,00  ...                      09:01:00   \n",
      "3        FORRAMENTO                   1,00  ...                      00:00:00   \n",
      "4           SIMPLES                   1,00  ...                      09:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PTS HORÁRIO DE SOLICITAÇÃO DO BLOQUEIO  \\\n",
      "0                    17:10:00                           00:00:00   \n",
      "1                    19:40:00                           00:00:00   \n",
      "2                    09:05:00                           00:00:00   \n",
      "3                    00:00:00                           00:00:00   \n",
      "4                    09:40:00                           09:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DO BLOQUEIO HORÁRIO DE SOLICITAÇÃO DA LIMPEZA  \\\n",
      "0                         00:00:00                          00:00:00   \n",
      "1                         00:00:00                          00:00:00   \n",
      "2                         00:00:00                          00:00:00   \n",
      "3                         00:00:00                          00:00:00   \n",
      "4                         09:30:00                          00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA LIMPEZA HORÁRIO DE SOLICITAÇÃO DA OM  \\\n",
      "0                        00:00:00                     00:00:00   \n",
      "1                        00:00:00                     00:00:00   \n",
      "2                        00:00:00                     00:00:00   \n",
      "3                        00:00:00                     00:00:00   \n",
      "4                        00:00:00                     00:00:00   \n",
      "\n",
      "  HORÁRIO DE RECEBIMENTO DA OM HORÁRIO DE SOLICITAÇÃO DA PET  \\\n",
      "0                     00:00:00                      00:00:00   \n",
      "1                     00:00:00                      00:00:00   \n",
      "2                     00:00:00                      00:00:00   \n",
      "3                     00:00:00                      00:00:00   \n",
      "4                     00:00:00                      00:00:00   \n",
      "\n",
      "  HORÁRIO DE LIBERAÇÃO DA PET  \n",
      "0                    00:00:00  \n",
      "1                    00:00:00  \n",
      "2                    00:00:00  \n",
      "3                    00:00:00  \n",
      "4                    00:00:00  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Colunas reorganizadas com sucesso em: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\relatorio_tratado.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Função para reorganizar as colunas conforme nova lógica\n",
    "def reorganizar_colunas_nova_logica(arquivo_excel):\n",
    "    # Verificar se o arquivo Excel existe\n",
    "    if not arquivo_excel.exists():\n",
    "        print(f\"Erro: O arquivo '{arquivo_excel}' não foi encontrado.\")\n",
    "        return\n",
    "\n",
    "    # Carregar o arquivo Excel\n",
    "    try:\n",
    "        df = pd.read_excel(arquivo_excel)\n",
    "        print(\"Arquivo carregado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o arquivo: {e}\")\n",
    "        return\n",
    "\n",
    "    # Exibir as primeiras linhas para depuração\n",
    "    print(\"Primeiras linhas do arquivo:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Verificar se existem pelo menos 31 colunas\n",
    "    if len(df.columns) < 31:\n",
    "        print(\"Erro: O arquivo precisa ter pelo menos 31 colunas.\")\n",
    "        return\n",
    "\n",
    "    # Identificar a coluna de índice 31 (considerando a indexação 0)\n",
    "    coluna_31 = df.columns[30]  # 31ª coluna (index 30)\n",
    "\n",
    "    # Mover a coluna 31 para a 4ª posição (index 3)\n",
    "    df.insert(3, coluna_31, df.pop(coluna_31))  # Move para a 4ª posição\n",
    "\n",
    "    # Exibir as primeiras linhas após reorganizar\n",
    "    print(\"Primeiras linhas após reorganizar as colunas:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Salvar o arquivo modificado\n",
    "    try:\n",
    "        df.to_excel(arquivo_excel, index=False, engine='openpyxl')\n",
    "        print(f\"Colunas reorganizadas com sucesso em: {arquivo_excel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o arquivo: {e}\")\n",
    "\n",
    "\n",
    "# Determinar o diretório de trabalho atual e o caminho relativo do arquivo\n",
    "diretorio_atual = Path.cwd()\n",
    "arquivo_excel = diretorio_atual / \"relatorio_tratado.xlsx\"\n",
    "\n",
    "# Chamada para reorganizar as colunas conforme a nova lógica\n",
    "reorganizar_colunas_nova_logica(arquivo_excel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a54zi5a0Eqj3"
   },
   "source": [
    "Verificar a consistencial geral dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1737630448241,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "mgImTwT0Es6J",
    "outputId": "e22722ca-6e0b-41cc-9e79-800c4a78c40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos carregados com sucesso.\n",
      "Falhas registradas no arquivo: c:\\Users\\Administrador\\Desktop\\filtro espiral em jupyter\\falhas_encontradas.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Função para carregar os dados de ambos os arquivos\n",
    "def carregar_dados(arquivo_original, arquivo_tratado):\n",
    "    try:\n",
    "        # Verificar se os arquivos existem\n",
    "        if not arquivo_original.exists() or not arquivo_tratado.exists():\n",
    "            print(\"Erro: Um ou ambos os arquivos não foram encontrados.\")\n",
    "            return None, None\n",
    "\n",
    "        # Carregar os dados\n",
    "        df_original = pd.read_csv(arquivo_original)\n",
    "        df_tratado = pd.read_excel(arquivo_tratado, engine='openpyxl')\n",
    "        print(\"Arquivos carregados com sucesso.\")\n",
    "        return df_original, df_tratado\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar os arquivos: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Função para padronizar a data\n",
    "def padronizar_data(data):\n",
    "    try:\n",
    "        data = str(data).strip().replace(\" //\", \"/\").replace(\"//\", \"/\").replace(\"/ \", \"/\").replace(\" \", \"\")\n",
    "        if len(data.split(\"/\")) == 3:  # Se tem 3 partes (dia/mês/ano)\n",
    "            dia, mes, ano = data.split(\"/\")\n",
    "            if len(ano) == 2:\n",
    "                ano = \"20\" + ano\n",
    "            return datetime.strptime(f\"{dia}/{mes}/{ano}\", \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "        if len(data.split(\"/\")) == 2:  # Formato incompleto, adiciona o ano atual\n",
    "            data = data + \"/\" + str(datetime.now().year)\n",
    "            return datetime.strptime(data, \"%d/%m/%Y\").strftime(\"%d/%m/%Y\")\n",
    "        return data\n",
    "    except Exception:\n",
    "        return data\n",
    "\n",
    "# Função para padronizar os valores de quantidade\n",
    "def padronizar_valores(valor):\n",
    "    try:\n",
    "        if pd.isna(valor) or str(valor).strip() == \"\":\n",
    "            return \"0,00\"\n",
    "        if isinstance(valor, str):\n",
    "            valor = valor.strip().lower()\n",
    "            if not valor.replace('.', '').replace(',', '').isdigit():\n",
    "                return \"0,00\"\n",
    "        valor = float(valor)\n",
    "        return f\"{valor:.2f}\".replace('.', ',')\n",
    "    except Exception:\n",
    "        return \"0,00\"\n",
    "\n",
    "# Função para padronizar as horas\n",
    "def padronizar_horas(valor):\n",
    "    try:\n",
    "        if isinstance(valor, str) and valor.strip():\n",
    "            if len(valor) == 2 and valor.isdigit():\n",
    "                return f\"{valor}:00:00\"\n",
    "            elif len(valor) == 5 and \":\" in valor:\n",
    "                return f\"{valor}:00\"\n",
    "            elif len(valor) == 8 and \":\" in valor:\n",
    "                return valor\n",
    "        return \"00:00:00\"\n",
    "    except Exception:\n",
    "        return \"00:00:00\"\n",
    "\n",
    "# Função para verificar se os dados foram devidamente tratados\n",
    "def verificar_tratamento(df_original, df_tratado, colunas_tratamento, tipo_tratamento):\n",
    "    inconsistencias = []  # Lista para armazenar as inconsistências encontradas\n",
    "\n",
    "    for coluna in colunas_tratamento:\n",
    "        if coluna in df_original.columns and coluna in df_tratado.columns:\n",
    "            for index, valor in enumerate(df_original[coluna]):\n",
    "                valor_original = valor\n",
    "                valor_tratado = df_tratado[coluna].iloc[index]\n",
    "                valor_esperado = valor_tratado\n",
    "\n",
    "                # Realizar o tratamento dos dados para comparação\n",
    "                if tipo_tratamento == 'data':\n",
    "                    valor_tratado = padronizar_data(valor_tratado)\n",
    "                    valor_esperado = padronizar_data(valor_original)\n",
    "                elif tipo_tratamento == 'valor':\n",
    "                    valor_tratado = padronizar_valores(valor_tratado)\n",
    "                    valor_esperado = padronizar_valores(valor_original)\n",
    "                elif tipo_tratamento == 'hora':\n",
    "                    valor_tratado = padronizar_horas(valor_tratado)\n",
    "                    valor_esperado = padronizar_horas(valor_original)\n",
    "\n",
    "                # Verificar falhas no tratamento\n",
    "                if valor_tratado != valor_esperado:\n",
    "                    inconsistencias.append({\n",
    "                        \"linha\": index + 1,  # O índice da linha\n",
    "                        \"coluna\": coluna,\n",
    "                        \"valor_original\": valor_original,\n",
    "                        \"valor_tratado\": valor_tratado,\n",
    "                        \"valor_esperado\": valor_esperado\n",
    "                    })\n",
    "\n",
    "    return inconsistencias\n",
    "\n",
    "# Função para salvar as inconsistências em um arquivo de texto\n",
    "def salvar_falhas_em_arquivo(inconsistencias, arquivo_saida):\n",
    "    try:\n",
    "        with open(arquivo_saida, 'w') as f:\n",
    "            if inconsistencias:\n",
    "                for inconsistencia in inconsistencias:\n",
    "                    f.write(f\"Falha encontrada:\\n\")\n",
    "                    f.write(f\"Coluna: {inconsistencia['coluna']}\\n\")\n",
    "                    f.write(f\"Linha: {inconsistencia['linha']}\\n\")\n",
    "                    f.write(f\"Valor original: {inconsistencia['valor_original']}\\n\")\n",
    "                    f.write(f\"Valor tratado: {inconsistencia['valor_tratado']}\\n\")\n",
    "                    f.write(f\"Valor esperado: {inconsistencia['valor_esperado']}\\n\")\n",
    "                    f.write(\"-\" * 50 + \"\\n\")\n",
    "            else:\n",
    "                f.write(\"Nenhuma inconsistência encontrada.\\n\")\n",
    "        print(f\"Falhas registradas no arquivo: {arquivo_saida}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o arquivo de falhas: {e}\")\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "diretorio_atual = Path.cwd()\n",
    "arquivo_original = diretorio_atual / \"relatorio_final.csv\"\n",
    "arquivo_tratado = diretorio_atual / \"relatorio_tratado.xlsx\"\n",
    "arquivo_saida = diretorio_atual / \"falhas_encontradas.txt\"\n",
    "\n",
    "# Carregar os dados dos arquivos\n",
    "df_original, df_tratado = carregar_dados(arquivo_original, arquivo_tratado)\n",
    "\n",
    "# Verificar se os arquivos foram carregados corretamente\n",
    "if df_original is not None and df_tratado is not None:\n",
    "    # Definir as colunas que precisam ser verificadas\n",
    "    colunas_tratamento_data = [\"DATA DE EXECUÇÃO\"]\n",
    "    colunas_tratamento_valores = [\"QTD PESSOAS\", \"QUANTIDADE DE ANDAIMES\"]\n",
    "    colunas_tratamento_horas = [\"HORÁRIO DE DISPONIBILIDADE\", \"HORÁRIO DE INÍCIO DA ATIVIDADE\"]\n",
    "\n",
    "    # Verificar os dados conforme o tipo de tratamento\n",
    "    inconsistencias_data = verificar_tratamento(df_original, df_tratado, colunas_tratamento_data, 'data')\n",
    "    inconsistencias_valores = verificar_tratamento(df_original, df_tratado, colunas_tratamento_valores, 'valor')\n",
    "    inconsistencias_horas = verificar_tratamento(df_original, df_tratado, colunas_tratamento_horas, 'hora')\n",
    "\n",
    "    # Combinar todas as inconsistências\n",
    "    inconsistencias = inconsistencias_data + inconsistencias_valores + inconsistencias_horas\n",
    "\n",
    "    # Salvar as falhas em um arquivo de texto\n",
    "    salvar_falhas_em_arquivo(inconsistencias, arquivo_saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHyEU_2zLe8h"
   },
   "source": [
    "Correção de inconsistências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1737553496437,
     "user": {
      "displayName": "Thalles Bhering",
      "userId": "01880170429850833301"
     },
     "user_tz": 180
    },
    "id": "HBZY3jMnLh2U",
    "outputId": "4cee67fd-fcbb-4859-86ed-ef039e30a349"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/falhas_encontradas.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m valor\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Carregar o arquivo de falhas encontradas\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/falhas_encontradas.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     15\u001b[0m     falhas \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Carregar o arquivo de dados\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/falhas_encontradas.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Função para corrigir o valor no formato adequado (duas casas decimais com vírgula)\n",
    "def corrigir_valor(valor):\n",
    "    try:\n",
    "        # Verifica se o valor pode ser convertido em float e aplica o formato desejado\n",
    "        valor_corrigido = f\"{float(valor):.2f}\".replace('.', ',')\n",
    "        return valor_corrigido\n",
    "    except ValueError:\n",
    "        # Caso não consiga converter para float, retorna o valor original\n",
    "        return valor\n",
    "\n",
    "# Carregar o arquivo de falhas encontradas\n",
    "with open('/content/falhas_encontradas.txt', 'r') as file:\n",
    "    falhas = file.readlines()\n",
    "\n",
    "# Carregar o arquivo de dados\n",
    "df = pd.read_excel('/content/relatorio_tratado.xlsx')\n",
    "\n",
    "# Processar as falhas encontradas e corrigir os valores no DataFrame\n",
    "for i in range(len(falhas)):\n",
    "    linha = falhas[i].strip()\n",
    "\n",
    "    if 'Falha encontrada' in linha:\n",
    "        # Extrair as informações da falha\n",
    "        coluna = falhas[i + 1].split(\":\")[1].strip()\n",
    "        linha_falha = int(falhas[i + 2].split(\":\")[1].strip()) - 1  # Ajusta para índice 0 do pandas\n",
    "        valor_original = falhas[i + 3].split(\":\")[1].strip()\n",
    "        valor_tratado = falhas[i + 4].split(\":\")[1].strip()\n",
    "        valor_esperado = falhas[i + 5].split(\":\")[1].strip()\n",
    "\n",
    "        # Corrigir o valor no DataFrame com o valor esperado\n",
    "        if coluna in df.columns:  # Verificar se a coluna existe no DataFrame\n",
    "            df.at[linha_falha, coluna] = corrigir_valor(valor_esperado)\n",
    "\n",
    "# Salvar o arquivo corrigido\n",
    "df_corrigido = df.copy()  # Faz uma cópia do DataFrame já corrigido\n",
    "df_corrigido.to_excel('/content/relatorio_tratado_corrigido.xlsx', index=False)\n",
    "\n",
    "print(\"Arquivo tratado corrigido salvo em: /content/relatorio_tratado_corrigido.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMEby+LE62nM8OmcH+KYO4M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
